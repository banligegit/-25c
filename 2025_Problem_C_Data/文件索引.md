# 📑 奥运奖牌榜建模 - 文件索引与查询指南

## 🔍 按用途快速查找

### 如果我想...

#### 📌 "了解这个项目做了什么"
→ 读这个文件：[工作交接单.md](./工作交接单.md) ⭐
- 概要：交付物清单、核心成就、后续计划
- 用时：10分钟
- 目标用户：项目经理、非技术人员

#### 📊 "加载数据开始建模"
→ 使用这个文件：**`country_year_features.csv`** ⭐⭐⭐
```python
import pandas as pd
df = pd.read_csv('country_year_features.csv')
print(df.shape)  # (8618, 22)
```
- 8,618行 × 22列
- 包含所有需要的特征
- 立即可用于模型

#### 🔧 "理解数据的每一列"
→ 读这个文件：[完成总结.md](./完成总结.md) ⭐⭐
- 特征详解（Tier 1-3）
- 特征统计与相关性
- 建议的模型方法
- 用时：20-30分钟
- 目标用户：数据科学家、建模人员

#### 📚 "获取详细的技术细节"
→ 读这个文件：[数据清洗与特征提取说明书.md](./数据清洗与特征提取说明书.md)
- 完整的清洗步骤说明
- 缺失值处理详解
- 特征工程细节
- 用时：1小时（深度阅读）
- 目标用户：技术团队、质量审核

#### 💻 "快速开始使用数据"
→ 读这个文件：[README.md](./README.md)
- 快速参考
- 代码示例
- 关键指标速查表
- 用时：5-10分钟
- 目标用户：所有人

#### 🔄 "重新生成或修改特征"
→ 运行这个脚本：[complete_data_processing.py](./complete_data_processing.py)
```bash
python complete_data_processing.py
```
- 一站式处理：清洗+特征+验证
- 可修改处理策略
- 输出新的`country_year_features.csv`

#### ✅ "验证数据质量"
→ 运行这个脚本：[verify_features.py](./verify_features.py)
```bash
python verify_features.py
```
- 检查2024年数据准确性
- 统计缺失值
- 计算特征相关性

---

## 📂 文件分类详表

### 核心数据文件

| 文件名 | 大小 | 用途 | 优先级 |
|--------|------|------|--------|
| `country_year_features.csv` | 714.5 KB | **主分析数据集** | 🔴 最高 |
| `summerOly_athletes_cleaned.csv` | 10.5 MB | 清洗后运动员数据 | 🟡 中 |
| `summerOly_medal_counts_cleaned.csv` | 37.5 KB | 清洗后奖牌数据 | 🟡 中 |

### 处理脚本

| 文件名 | 行数 | 用途 | 运行命令 |
|--------|------|------|--------|
| `complete_data_processing.py` | 358 | 完整处理 (推荐) | `python complete_data_processing.py` |
| `data_cleaning.py` | 139 | 初始清洗 | `python data_cleaning.py` |
| `verify_features.py` | 128 | 特征验证 | `python verify_features.py` |

### 文档 (按推荐阅读顺序)

| 文件名 | 页数 | 内容摘要 | 阅读时间 |
|--------|------|--------|--------|
| `工作交接单.md` | 4 | 项目交接、交付物、快速开始 | 10分钟 ⭐ |
| `完成总结.md` | 8+ | 技术总结、特征详解、建议 | 30分钟 ⭐⭐ |
| `README.md` | 4 | 快速参考、使用示例 | 5分钟 |
| `数据清洗与特征提取说明书.md` | 7 | 详细技术文档 | 60分钟 |
| `本文件` (文件索引) | 5+ | 查询与导航 | 按需 |

### 原始数据 (不推荐直接使用)

| 文件名 | 大小 | 备注 |
|--------|------|------|
| `summerOly_athletes.csv` | 23 MB | 原始未清洗 |
| `summerOly_medal_counts.csv` | 37 KB | 原始未清洗 |
| `summerOly_hosts.csv` | 1.2 KB | 原始数据 |
| `summerOly_programs.csv` | 7.4 KB | 原始数据 |
| `data_dictionary.csv` | 3.7 KB | 数据字典 |

---

## 🎯 按角色推荐阅读

### 👨‍💼 项目经理
**目标**：理解项目进展和交付物
1. [工作交接单.md](./工作交接单.md) - 项目完成情况
2. [README.md](./README.md) - 快速指南

**关键数字**：
- ✅ 数据清洗：删除139,418条重复和不讨论国家的数据
- ✅ 特征提取：生成8,618条完整特征记录
- ✅ 数据验证：2024年数据与赛题完全一致
- ⏭️ 下一步：开始模型建立

---

### 👨‍💻 数据科学家 / 建模人员
**目标**：快速加载数据并构建模型
1. [README.md](./README.md) - 2分钟快速入门
2. [完成总结.md](./完成总结.md) - 理解特征体系
3. `country_year_features.csv` - 直接建模

**快速代码**：
```python
import pandas as pd
df = pd.read_csv('country_year_features.csv')

# 过滤训练集和验证集
train = df[(df['Year'] <= 2020) & (df['Lag_1_Total'].notna())]
val = df[df['Year'] == 2024]

# 建模
from sklearn.ensemble import RandomForestRegressor
model = RandomForestRegressor()
model.fit(train[['Lag_1_Gold', 'Athlete_Count', 'Is_Host']], 
          train['Gold_Medals'])

# 预测
pred = model.predict(val[['Lag_1_Gold', 'Athlete_Count', 'Is_Host']])
```

---

### 🔬 数据工程师 / 质量审核
**目标**：理解数据处理细节和验证数据质量
1. [数据清洗与特征提取说明书.md](./数据清洗与特征提取说明书.md) - 完整技术文档
2. [complete_data_processing.py](./complete_data_processing.py) - 代码审查
3. 运行 [verify_features.py](./verify_features.py) - 数据质量检查

**关键检查清单**：
- ✅ 2024年数据对标
- ✅ 缺失值处理
- ✅ 特征相关性
- ✅ 东道主效应

---

### 👨‍🏫 教学 / 论文指导
**目标**：了解整个数据处理过程
1. [完成总结.md](./完成总结.md) - 整体流程
2. [数据清洗与特征提取说明书.md](./数据清洗与特征提取说明书.md) - 详细步骤
3. 查看脚本代码 - 学习实现细节

**推荐材料**：
- 数据清洗的17个国家处理策略
- 团体项目去重的解决方案
- 特征工程的最佳实践

---

## 📋 文件映射表

### 如果我想查询关于..."X"的信息

| 主题 | 相关文件 | 页码/行号 |
|------|--------|---------|
| 清洗了哪些国家 | [完成总结.md](./完成总结.md) | 第2节 |
| 特征有哪些 | [README.md](./README.md) | 【特征工程清单】 |
| 2024年数据准确性 | [工作交接单.md](./工作交接单.md) | 【数据质量检查】 |
| 东道主效应 | [完成总结.md](./完成总结.md) | 【特征体系详解-Tier 2.3】 |
| 缺失值处理 | [数据清洗与特征提取说明书.md](./数据清洗与特征提取说明书.md) | 【缺失值处理策略】 |
| 如何建模 | [完成总结.md](./完成总结.md) | 【后续工作建议】 |
| 历史数据验证 | [工作交接单.md](./工作交接单.md) | 【数据质量检查清单】 |
| 运动员特征 | [完成总结.md](./完成总结.md) | 【Tier 2.2】 |
| 教练效应 | [完成总结.md](./完成总结.md) | 【Tier 3.2】 |

---

## 📞 常见查询

### "我需要..."

#### 数据本身
```
Q: 我需要用来建模的数据
A: 使用 country_year_features.csv
   • 8,618 行 × 22 列
   • 包含所有必要特征
   • 可直接用于模型
```

#### 代码实现
```
Q: 我需要看数据处理的代码
A: 查看 complete_data_processing.py
   • 清洗逻辑：第1-2节
   • 特征提取：第3-10节
   • 验证方法：第11节
```

#### 文档说明
```
Q: 我需要理解特征的含义
A: 查看 完成总结.md 的"特征体系详解"
   • Tier 1: 目标变量
   • Tier 2: 强势预测特征
   • Tier 3: 辅助特征
```

#### 技术细节
```
Q: 我需要了解团体项目怎么处理的
A: 查看 数据清洗与特征提取说明书.md 的【数据清洗】->【1.2】
   • 问题说明
   • 解决方案
   • 效果统计 (删除125,813条)
```

#### 数据质量
```
Q: 数据准不准确？
A: 查看 工作交接单.md 的【数据质量检查清单】
   • 2024年与赛题完全一致 ✅
   • 时间序列完整 ✅
   • 缺失值处理合理 ✅
```

---

## 🚀 快速导航

### 开始您的之旅（选择一条路径）

#### 🛣️ 路径1：我想快速上手
```
第1步 → README.md (5分钟)
第2步 → 加载 country_year_features.csv
第3步 → 写简单的模型代码
第4步 → 查看结果
```

#### 🛣️ 路径2：我想深入理解
```
第1步 → 工作交接单.md (10分钟)
第2步 → 完成总结.md (30分钟)
第3步 → 数据清洗与特征提取说明书.md (60分钟)
第4步 → 查看脚本代码
第5步 → 加载数据并验证
```

#### 🛣️ 路径3：我想复现整个过程
```
第1步 → 读 README.md 和工作交接单.md
第2步 → 阅读 data_cleaning.py
第3步 → 阅读 complete_data_processing.py
第4步 → 阅读 verify_features.py
第5步 → 修改参数重新运行处理脚本
第6步 → 对比新旧结果
```

#### 🛣️ 路径4：我想质量审核
```
第1步 → 完成总结.md 【关键成就】部分
第2步 → 运行 verify_features.py
第3步 → 查看输出数据质量报告
第4步 → 读详细说明书确认处理策略
```

---

## 🔗 相关链接

### 项目文档
- [MCM/ICM 2025赛题](https://www.comap.org/) - 原始赛题
- [奥运数据来源](https://en.wikipedia.org/wiki/Olympic_Games) - 数据参考

### Python库文档
- [Pandas](https://pandas.pydata.org/) - 数据处理
- [Scikit-learn](https://scikit-learn.org/) - 机器学习
- [Statsmodels](https://www.statsmodels.org/) - 统计模型

---

## 📝 笔记区

在此处添加您的笔记和发现：

```
[留白供用户添加笔记]
```

---

**上次更新**：2026年1月21日  
**版本**：1.0  
**维护者**：数据处理团队

